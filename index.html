<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Debug Face Tracker</title>
    <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api@1.7.12/dist/face-api.js"></script>
    <style>
        body { margin: 0; background: #000; color: #00bcff; font-family: sans-serif; display: flex; flex-direction: column; align-items: center; justify-content: center; height: 100vh; }
        #container { position: relative; border: 2px solid #333; }
        canvas { position: absolute; top: 0; left: 0; }
        #status { padding: 10px; text-align: center; }
    </style>
</head>
<body>

    <div id="status">Checking Environment...</div>
    <div id="container">
        <video id="video" width="640" height="480" autoplay muted playsinline></video>
        <canvas id="overlay"></canvas>
    </div>

    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('overlay');
        const status = document.getElementById('status');

        async function start() {
            try {
                // Check if running via file://
                if (window.location.protocol === 'file:') {
                    alert("SECURITY ERROR: You cannot run AI models by double-clicking the file. Please use a 'Live Server' or upload to CodePen.");
                    status.innerText = "Error: Use a Local Server";
                    return;
                }

                status.innerText = "Downloading AI Models (6MB)...";
                const MODEL_URL = 'https://cdn.jsdelivr.net/npm/@vladmandic/face-api@1.7.12/model/';
                
                await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
                await faceapi.nets.ageGenderNet.loadFromUri(MODEL_URL);

                status.innerText = "Requesting Camera...";
                const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
                video.srcObject = stream;

                video.onplay = () => {
                    const displaySize = { width: video.width, height: video.height };
                    faceapi.matchDimensions(canvas, displaySize);
                    
                    setInterval(async () => {
                        const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withAgeAndGender();
                        const resized = faceapi.resizeResults(detections, displaySize);
                        const ctx = canvas.getContext('2d');
                        ctx.clearRect(0, 0, canvas.width, canvas.height);
                        
                        resized.forEach(det => {
                            ctx.strokeStyle = '#00bcff';
                            ctx.lineWidth = 4;
                            ctx.strokeRect(det.box.x, det.box.y - 40, det.box.width, det.box.width);
                            ctx.fillStyle = '#00bcff';
                            ctx.fillText(`Age: ${Math.round(det.age)}`, det.box.x, det.box.y - 50);
                        });
                    }, 100);
                    status.innerText = "Running!";
                };

            } catch (e) {
                status.innerText = "Fatal Error: " + e.message;
                console.error(e);
            }
        }

        start();
    </script>
</body>
</html>
